{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f790b51-f01b-487a-9635-538d0cbecd66",
   "metadata": {},
   "source": [
    "### Script preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24c4f7-fd0c-47d0-af9e-4c2742849aee",
   "metadata": {},
   "source": [
    "This part is for the explainability module. Using this code, you can use local interpretable model-agnostic explanations (LIME) to check for/derive biological meaning from predictions for patients.\n",
    "\n",
    "Make sure you have installed all other packages in the main pipeline. Install the packages required for this code:\n",
    "1. \"lime\" v0.2.0.1 to implement LIME algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73382c-8316-4f6c-b95b-ef1c30e85059",
   "metadata": {},
   "source": [
    "This phrase indicates an input requirement that must be fulfilled by you.\n",
    "<font color='orange'>\"**INPUT:**\"<font>\n",
    "\n",
    "Other cells do not require any alterations and should be run without any change in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dcae4-0be6-47b8-97d1-10e34b3315af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1bff5-b79c-4fc1-9f0e-8430474277ba",
   "metadata": {},
   "source": [
    "Import the required packages for the entire code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8040418-0d16-40f1-866a-9126e6d23a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold\n",
    "import seaborn as sns\n",
    "import flowio\n",
    "import flowutils\n",
    "import FlowCal\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e0e03-0d53-4d38-8a04-c002aad8deaf",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea7a6a-73a7-4f82-86b2-90bfb2386326",
   "metadata": {},
   "source": [
    "A few notes:\n",
    "1. Have the original training dataset at hand as it is needed by LIME..\n",
    "2. The runtime for each patient will be 10-20 minutes depending on your system's specs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b4cc4-acf1-4e5e-9df1-4fbb86738b2b",
   "metadata": {},
   "source": [
    "<font color='orange'>**INPUT:** Load the training dataset into a pandas DataFrame. Insert the training dataset name like below:\n",
    "\n",
    "*dataset_name = 'example.csv'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969451a6-544f-4afe-87d5-842f034dd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Sample_training_dataset.csv'    \n",
    "data = pd.read_csv(dataset_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9de588-e7a7-496c-a1a0-2539e30d5aab",
   "metadata": {},
   "source": [
    "Define the training data, labels, and group labels. The \"Population\" is the column with annotations and the \"Batch\" is the column with patient or batch ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a23d1a-b799-4730-a9dd-2ecb19d052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Population', 'FSC-H', 'Batch'], axis=1)\n",
    "y = data['Population']\n",
    "groups = data['Batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51eb6ba-d2a0-43aa-917e-1dc1f1d650ed",
   "metadata": {},
   "source": [
    "### Testing with explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e2628-176a-4286-a342-d70e290947b2",
   "metadata": {},
   "source": [
    "A function for analyzing test FCS files, saving a table of percentages populations present, saving desired figures, as well as a explainability matrix by LIME. \n",
    "\n",
    "<font color='orange'>Please read the comment at line 29.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cbd3ca-ade3-489c-b247-b357941772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(address, ml_model, dotplot_num, dotplot_params):\n",
    "    file_address = address\n",
    "    global file_name\n",
    "    file_name = file_address.replace('.fcs', '')\n",
    "    fcs_file = flowio.FlowData(file_address)\n",
    "    try:\n",
    "        spill, markers = flowutils.compensate.get_spill(fcs_file.text['spill'])\n",
    "    except KeyError:\n",
    "        spill, markers = flowutils.compensate.get_spill(fcs_file.text['spillover'])\n",
    "    raw_data = np.reshape(fcs_file.events, (-1, fcs_file.channel_count))\n",
    "    fluoro_indices = []\n",
    "    for channel in fcs_file.channels:\n",
    "        if fcs_file.channels[channel]['PnN'] in markers:\n",
    "            fluoro_indices.append(int(channel) - 1)\n",
    "    fluoro_indices.sort()\n",
    "    comp_data = flowutils.compensate.compensate(raw_data, spill, fluoro_indices)\n",
    "    channel_list = []\n",
    "    for i in range(1, fcs_file.channel_count + 1):\n",
    "        channel_list.append(fcs_file.text['p{}n'.format(i)])\n",
    "    flow_data = FlowCal.transform.to_rfi(comp_data, amplification_type=(tuple([(0, 0)] * len(channel_list))))\n",
    "    events = pd.DataFrame(flow_data, columns=channel_list)\n",
    "    total_events = events.loc[events['FSC-A'] / events['FSC-H'] < 2]\n",
    "    for ch in ['FSC-H', 'SSC-H', 'Time']:\n",
    "        try:\n",
    "            total_events.drop(columns=[ch], inplace=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    model = ml_model\n",
    "    \n",
    "    # READ ME:\n",
    "    # If you want to test the sample files (csv and fcs), to match the columns between the training dataset and sample fcs,\n",
    "    # run the the next line of code as well (remove # from the beginning).\n",
    "    #total_events = total_events[['FSC-A', 'SSC-A', 'FITC-A', 'PE-A', 'PerCP-Cy5.5-A', 'PE-Cy7-A', 'APC-A', 'APC-R700-A', 'APC-Cy7-A', 'V450-A', 'V500-C-A']]\n",
    "    total_events['Predicted'] = model.predict(total_events)\n",
    "    global wbc_events\n",
    "    wbc_events = total_events.loc[(total_events['Predicted'] != 'Erythroid Cells') & (total_events['Predicted'] != 'Erythroid Precursors')]\n",
    "    results = wbc_events['Predicted'].value_counts(normalize=True) * 100\n",
    "    results.to_csv('{} results.csv'.format(file_name))\n",
    "    global mrd_events\n",
    "    mrd_events = wbc_events.loc[wbc_events['Predicted'] == 'Residual Leukemic Cells']\n",
    "    for n in range(dotplot_num):\n",
    "        dot_plot(dotplot_params[n][0], dotplot_params[n][1])\n",
    "    i_list = list(total_events.columns)\n",
    "    del i_list[-1]\n",
    "    explanation = pd.DataFrame(index=range(len(i_list)))\n",
    "    for p in sorted(list(total_events['Predicted'].value_counts().index)):\n",
    "        pop_events = total_events.loc[total_events['Predicted'] == p].copy()\n",
    "        try:\n",
    "            sub_events = pop_events.sample(1000, random_state=13)\n",
    "        except ValueError:\n",
    "            sub_events = pop_events.copy()\n",
    "        interp = pd.DataFrame(index=range(len(i_list)))\n",
    "        for e in range(len(sub_events.drop(columns='Predicted'))):\n",
    "            exp = explainer.explain_instance(np.array(sub_events.drop(columns='Predicted'))[e],\n",
    "                                             model.predict_proba,\n",
    "                                             top_labels=1)\n",
    "            df = pd.DataFrame(exp.as_map()[exp.available_labels()[0]], columns=['Label', 'Value'])\n",
    "            df = df.sort_values('Label').set_index('Label')\n",
    "            interp['Event ' + str(e)] = df['Value']\n",
    "        interp.fillna(0, inplace=True)\n",
    "        interp = interp.T\n",
    "        interp.loc['Value'] = interp.mean()\n",
    "        interp = interp.T\n",
    "        explanation[p] = list(interp['Value'].values)\n",
    "    explanation.index = i_list\n",
    "    explanation = (explanation - explanation.min()) / (explanation.max() - explanation.min())\n",
    "    ax = sns.heatmap(explanation, cmap='Purples', annot=True, fmt='.2f', annot_kws={'size': 6})\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Explainability Matrix: Patient ' + file_name)\n",
    "    plt.savefig(f'{file_name} Explainability matrix heatmap.png', bbox_inches='tight', dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8578af2-d1a5-48bc-ad28-36371d208c14",
   "metadata": {},
   "source": [
    "A function for creating and saving figures showing the MRD population based on your parameters of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ae0983-8e4e-43d1-9047-6df3eb975e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_plot(x, y):\n",
    "    sns.scatterplot(x=wbc_events[x], y=wbc_events[y], c='lightgrey', s=1)\n",
    "    sns.scatterplot(x=mrd_events[x], y=mrd_events[y], c='maroon', s=3)\n",
    "    if x in ['FSC-A', 'SSC-A']:\n",
    "        plt.xscale('linear')\n",
    "    else:\n",
    "        plt.xscale('symlog', linthresh=1000)\n",
    "        plt.xlim(left=-1000)\n",
    "    if y in ['FSC-A', 'SSC-A']:\n",
    "        plt.yscale('linear')\n",
    "    else:\n",
    "        plt.yscale('symlog', linthresh=1000)\n",
    "        plt.ylim(bottom=-1000)\n",
    "    plt.savefig('{}-{}-{}.png'.format(file_name, x, y))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315f960-0c1d-47cb-931f-91c11ce5e2b8",
   "metadata": {},
   "source": [
    "<font color='orange'>**INPUT:** Load the model from a saved pickle object. Insert the model name like below:\n",
    "\n",
    "*model_name = 'example.pkl'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c01ba54-937f-4817-84e9-1325efc49a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Sample_model.pkl' \n",
    "model = pickle.load(open(model_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020bc2f-f246-4c5e-be41-90e4c539c827",
   "metadata": {},
   "source": [
    "Define the LIME explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f79468-d23b-4309-b746-3c631ecd336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(np.array(X),\n",
    "                                                   feature_names=list(model.feature_names_in_),\n",
    "                                                   class_names=list(model.classes_),\n",
    "                                                   discretize_continuous=True,\n",
    "                                                   random_state=13,\n",
    "                                                   verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98fc08-0155-4cb1-9c22-64fed6e4c252",
   "metadata": {},
   "source": [
    "<font color='orange'>**INPUT:** Analyze a single fcs file. Add the name of the file, indicate the number of figures you want and the parameters in figures like below:\n",
    "\n",
    "*file_name = 'example.fcs'*\n",
    "\n",
    "*fig_num = 2*\n",
    "\n",
    "*fig_params = [('FSC-A', 'SSC-A'), ('V500-C-A', 'SSC-A')]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e0c50c-27f4-4bdd-b869-9e45c308afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Sample_patient.fcs'\n",
    "fig_num = 2\n",
    "fig_params = [('FSC-A', 'SSC-A'), ('V500-C-A', 'SSC-A')]\n",
    "analyze(file_name, model, fig_num, fig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354d35d-ec41-4ec2-8919-8250dad8edda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
